{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "import chardet\n",
    "import pandas\n",
    "\n",
    "def read_fbp_to_csv(fbp_file_path, csv_file_path):\n",
    "    # Lesen der FBP-Datei und Schreiben der Daten in die CSV-Datei\n",
    "    with open(fbp_file_path, 'r', encoding='ISO-8859-1') as fbp_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        # CSV-Writer-Objekt erstellen\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Jede Zeile der FBP-Datei lesen\n",
    "        for line in fbp_file:\n",
    "            # Zeilen aufteilen, wobei \"|\" als Trennzeichen verwendet wird\n",
    "            fields = line.strip().split(\"|\")\n",
    "            # Zeile in die CSV-Datei schreiben\n",
    "            csv_writer.writerow(fields)\n",
    "\n",
    "# FBP- und CSV-Dateipfade\n",
    "fbp_file_path = 'Auslandsdaten1.fbp'\n",
    "csv_file_path = 'Auslandsdaten1.csv'\n",
    "\n",
    "# Die ersten paar Bytes der Datei lesen, um die Kodierung zu ermitteln\n",
    "rawdata = open(fbp_file_path, \"rb\").read(10000)  # Die ersten 10.000 Bytes lesen\n",
    "result = chardet.detect(rawdata)\n",
    "charenc = result['encoding']\n",
    "# Funktion aufrufen\n",
    "read_fbp_to_csv(\"Auslandsdaten1.fbp\", \"Auslandsdaten1.csv\")\n",
    "read_fbp_to_csv(\"Auslandsdaten2.fbp\", \"Auslandsdaten2.csv\")\n",
    "#read in the csv file skip the first row of the csv file\n",
    "df = pandas.read_csv(\"Auslandsdaten1.csv\", skiprows=0, encoding=charenc)\n",
    "#drop the first 2 columns\n",
    "df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "# \n",
    "#benenne den header so um:\n",
    "# C1,C2A,C2B,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27\n",
    "df.columns = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B9\",\"B10\",\"B11\",\"B12\",\"B13\",\"B14\",\"B15\",\"B16\"]\n",
    "#speicher die datei als Ausland1neu.csv\n",
    "df.to_csv('Ausland1neu.csv', index=False)\n",
    "\n",
    "df = pandas.read_csv(\"Auslandsdaten2.csv\", skiprows=1, encoding=charenc)\n",
    "#drop the first 2 columns\n",
    "df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "#benenne den header so um:\n",
    "# C1,C2A,C2B,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27\n",
    "df.columns = [\"C1\",\"C2A\",\"C2B\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\",\"C12\",\"C13\",\"C14\",\"C15\",\"C16\",\"C17\", \"C18\",\"C19\",\"C20\",\"C21\",\"C22\",\"C23\",\"C24\",\"C25\",\"C26\",\"C27\"]\n",
    "#speicher die datei als Ausland1neu.csv\n",
    "df.to_csv('Ausland2neu.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d83522877d387d7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "#berechne die aktuelle startzeit\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#check if a A.csv, B.csv, C.csv, D.csv und E.csv datei exisieren wenn ja dann lass sie wenn nein erstell sie neu\n",
    "path = \"../../DE1D_2023_06_13\"\n",
    "\n",
    "with open(path+\"/D.csv\", \"w\") as file:\n",
    "    file.write(\"D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12A,D12B,D12C,D13,D14A,D15\\n\")\n",
    "\n",
    "with open(path+\"/E.csv\", \"w\") as file:\n",
    "    file.write(\"E1,E3,E4,E5,E6,E7,E8,E9,E10,E11,E12A,E12B,E12C,E13,E14,E15\\n\")\n",
    "\n",
    "dataframe_a = pandas.read_csv(path+\"/A.csv\", sep=',', header=0)\n",
    "dataframe_b = pandas.read_csv(path+\"/Ausland1neu.csv\", sep=',', header=0) #Ausland1neu -> B\n",
    "dataframe_c = pandas.read_csv(path+\"/Ausland2neu.csv\", sep=',', header=0) #Ausland2neu -> C\n",
    "dataframe_b[\"B14\"] = \"N\"*50 #LÖSCHEN!\n",
    "dataframe_c[\"C20\"] = \"N\"*50 #LÖSCHEN!\n",
    "dataframe_c[\"C21\"] = \"N\"*50 #LÖSCHEN!\n",
    "dataframe_d = pandas.read_csv(path+'/D.csv', sep=',', header=0)\n",
    "dataframe_e = pandas.read_csv(path+'/E.csv', sep=',', header=0)\n",
    "\n",
    "\n",
    "def C_20_Pos13(row):\n",
    "    B_Satz2Row = dataframe_b.loc[dataframe_b[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list = list(row[\"C20\"])\n",
    "    temp_list[12] = \"Y\" if B_Satz2Row[\"B14\"][1] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list)\n",
    "\n",
    "\n",
    "dataframe_c[\"C20\"] = dataframe_c.apply(C_20_Pos13, axis=1)\n",
    "\n",
    "# drop all values from dataframe_d\n",
    "#dataframe_d = dataframe_d.iloc[0:0]\n",
    "# kundennummer bei B2 und C2A verbinde dort nicht alle C2A sind in B2 enthalten\n",
    "dataframe_b['B2'] = dataframe_b['B2'].astype(str)\n",
    "dataframe_c['C2A'] = dataframe_c['C2A'].astype(str)\n",
    "dataframe_d['D1'] = 'D'\n",
    "dataframe_b[\"B1\"] = \"B\"\n",
    "dataframe_c[\"C1\"] = \"C\"\n",
    "dataframe_a[\"A1\"] = \"A\"\n",
    "\n",
    "def generate_a_b_c_data():\n",
    "    global dataframe_a_b_c\n",
    "    global dataframe_b_c\n",
    "    # verbinde die den dataframe B und C anhand der werte aus B2 und C2A\n",
    "    dataframe_b_c = pandas.merge(dataframe_b, dataframe_c, left_on='B2', right_on='C2A', how='inner')\n",
    "    # Repliziere dataframe_a für die Anzahl der Zeilen in dataframe_b_c\n",
    "    df_a_repeated_for_b_c = pandas.concat([dataframe_a] * dataframe_b_c.shape[0], ignore_index=True)\n",
    "    # Verbinde df_a_repeated_for_b_c horizontal mit dataframe_b_c\n",
    "    dataframe_a_b_c = pandas.concat([df_a_repeated_for_b_c, dataframe_b_c], axis=1)\n",
    "    # save dataframe b to csv\n",
    "generate_a_b_c_data()\n",
    "#######D2########\n",
    "# trage in D2 die einzigartigen werte aus B2 ein\n",
    "dataframe_d['D2'] = dataframe_a_b_c['B2'].unique()\n",
    "\n",
    "#######D3#######\n",
    "# D3 hat die summe aller werte aus C19 abhängig von der kundennummer\n",
    "dataframe_d['D3'] = dataframe_a_b_c.groupby('B2')['C19'].transform('sum')\n",
    "#######D4-15#######\n",
    "def compute_d_group(group, df_d):\n",
    "    # Initialize D4 value\n",
    "    D4_value = 0.00\n",
    "    D3_value = df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0]\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in ['01', '10']:\n",
    "\n",
    "        # Check if any value in B14 (range \"01\" to \"30\") is \"Y\"\n",
    "        if any(\"Y\" in s for s in group['B14'].str[0:30]):\n",
    "            D4_value = group['C19'].sum()\n",
    "        elif int(df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0]) < 20 and group['C20'].iloc[0] == 'Y':\n",
    "            D4_value = df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0]\n",
    "        elif any(\"Y\" in s for s in group['C20'].str[1:30]):\n",
    "            D4_value = group['C19'].sum()\n",
    "    else:\n",
    "        D4_value = 0.00\n",
    "\n",
    "    # Set D4 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D4'] = D4_value\n",
    "\n",
    "    D5_value = 0.00\n",
    "\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in ['01', '10']:\n",
    "        # Calculate D3 divided by D4\n",
    "        if D4_value != 0:\n",
    "            D5_value = D3_value / D4_value\n",
    "    else:\n",
    "        D5_value = 0.00\n",
    "\n",
    "    # Set D5 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D5'] = D5_value\n",
    "\n",
    "\n",
    "    D6_value = 0.00\n",
    "\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in ['01', '10']:\n",
    "        # Get the D5 value\n",
    "        # Calculate the limit which is A4 * C5\n",
    "        limit_value = group['A4'].iloc[0] * group['C5'].iloc[0]\n",
    "        # Set D6 to be the minimum of D5 and the limit value\n",
    "        D6_value = min(D5_value, limit_value)\n",
    "    else:\n",
    "        D6_value = 0.00\n",
    "\n",
    "    # Set D6 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D6'] = D6_value\n",
    "\n",
    "    D7_value = 0.00\n",
    "\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in [\"01\", \"10\"]:\n",
    "        # Get the D5 and D6 values\n",
    "        # Avoid division by zero\n",
    "        if D6_value != 0:\n",
    "            D7_value = D5_value / D6_value\n",
    "    else:\n",
    "        D7_value = 0.00\n",
    "\n",
    "    # Set D7 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D7'] = D7_value\n",
    "\n",
    "    D8_value = 0.00\n",
    "    if pandas.notnull(group['C22'].iloc[0]) and group['C22'].iloc[0] != \"DE\":\n",
    "        D8_value = group['C19'].sum()\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D8'] = D8_value\n",
    "\n",
    "    D9_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) == \"20\":\n",
    "        limit_value = group['A5'].iloc[0] * group['C5'].iloc[0]\n",
    "        D9_value = min(df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0], limit_value)\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D9'] = D9_value\n",
    "\n",
    "    D10_value = 0.00\n",
    "\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        D10_value = group[group['C27'] == 10]['C19'].sum()\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D10'] = D10_value\n",
    "\n",
    "    D11_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        D11_value = group[group['C27'] == 20]['C19'].sum() - group['C26'].sum()\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D11'] = D11_value\n",
    "\n",
    "\n",
    "    D14A_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        # Sum of debitorische Kontosalden from C19\n",
    "        D14A_value = -group['C19'].sum()\n",
    "    else:\n",
    "        D14A_value = 0.00\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D14A'] = D14A_value\n",
    "\n",
    "    wert1 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D3'].iloc[0]\n",
    "    wert2 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D10'].iloc[0]\n",
    "    wert3 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D14A'].iloc[0]\n",
    "    wert4 = max(df_d.loc[df_d['D2'] == group['B2'].iloc[0], ['D6', 'D9', 'D11']].iloc[0])\n",
    "    HW1 = wert1 - wert2 + wert3 - wert4\n",
    "    D12A_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        wert5 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D6'].iloc[0] + df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D9'].iloc[0]\n",
    "        if wert5 != 0:\n",
    "            limit_value = (group['A6C'].iloc[0] * group['C5'].iloc[0]) / wert5\n",
    "            D12A_value = min(HW1, limit_value)\n",
    "        else:\n",
    "            D12A_value = HW1\n",
    "        if D12A_value < 0:\n",
    "            D12A_value = 0.00\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D12A'] = D12A_value\n",
    "\n",
    "    D12B_value = 0.00\n",
    "    HW2 = group[(group['C27'].isin(['01', '90'])) & (group['C21'].str[18] == 'Y')]['C19'].sum()\n",
    "    # Berechne HW3\n",
    "    HW3_1 = group[(group['C27'] == '90') & (group['C21'].str[10] == 'N') & (group['C21'].str[18] == 'N')]['C19'].sum()\n",
    "    HW3_2 = group[group['C27'] == '20']['C19'].sum()\n",
    "    HW3 = HW3_1 + HW3_2\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"] and pandas.notnull(group['A8'].iloc[0]):\n",
    "        # Berechne HW2\n",
    "        # Werte für die Berechnung\n",
    "        A9_value = group['A9A'].iloc[0]\n",
    "        C5_value = group['C5'].iloc[0]\n",
    "\n",
    "        # Berechne die drei möglichen Werte für D12B\n",
    "        value1 = HW1 / D12A_value\n",
    "        value2 = HW2 / (D6_value + D9_value / HW3) if HW3 != 0 and (D6_value + D9_value / HW3) > 0 else HW2\n",
    "        value3 = A9_value * C5_value / (D6_value + D9_value + D12A_value)\n",
    "\n",
    "        # Setze D12B auf den kleinsten Wert\n",
    "        D12B_value = min(value1, value2, value3)\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D12B'] = D12B_value\n",
    "\n",
    "    D12C_value = 0.00\n",
    "\n",
    "    #convert c27 to string\n",
    "\n",
    "    # Berechne HW4\n",
    "    HW4 = group[(group['C27'].astype(str).isin(['01', '90'])) & (group['C21'].str[10] == 'Y')]['C19'].sum()\n",
    "\n",
    "    # Berechne HW5\n",
    "    HW5_1 = group[(group['C27'].astype(str) == '90') & (group['C21'].str[10] == 'N')]['C19'].sum()\n",
    "    HW5_2 = group[group['C27'].astype(str) == '20']['C19'].sum()\n",
    "    HW5 = HW5_1 + HW5_2\n",
    "\n",
    "\n",
    "\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"] and any('Y' == c for c in group['C21'].str[10]) and HW1 < int(group['A6C'].iloc[0]) * group['C5'].sum():  #welcher c5 wert soll genommen werden\n",
    "        # Werte für die Berechnung\n",
    "        C5_value = group['C5'].iloc[0]\n",
    "        A7_value = group['A7'].iloc[0]\n",
    "\n",
    "        wert2 = HW4 / ((D6_value + D9_value) / HW5) if (D6_value + D9_value) / HW5 > 0 else HW4\n",
    "        wert3 = A7_value * C5_value / (D6_value + D9_value + D12A_value + D12B_value)\n",
    "\n",
    "        # Setze D12C auf den kleinsten Wert\n",
    "        D12C_value = min(wert1, wert2, wert3)\n",
    "        if D12C_value < 0:\n",
    "            D12C_value = 0.00\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D12C'] = D12C_value\n",
    "\n",
    "\n",
    "    D13_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        D13_value = D12A_value + D12B_value + D12C_value\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D13'] = D13_value\n",
    "\n",
    "\n",
    "    valid_entries = group.loc[pandas.isnull(group['C23'])]\n",
    "    D15_value = valid_entries['C19'].sum()\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D15'] = D15_value\n",
    "\n",
    "\n",
    "dataframe_a_b_c.groupby('B2').apply(compute_d_group, dataframe_d)\n",
    "\n",
    "dataframe_d['D1'] = 'D'\n",
    "dataframe_d.to_csv(path+'/D.csv', index=False)\n",
    "\n",
    "dataframe_e = pandas.DataFrame(columns=['E1', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12A', 'E12B', 'E12C', 'E13', 'E14', 'E15'])\n",
    "\n",
    "# Setze die Werte für die Spalten in E\n",
    "dataframe_e.at[0, 'E1'] = 'E'\n",
    "# E2 wird freigelassen, wie du erwähnt hast\n",
    "dataframe_e.at[0, 'E3'] = dataframe_d['D3'].sum()\n",
    "dataframe_e.at[0, 'E4'] = dataframe_d['D4'].sum()\n",
    "dataframe_e.at[0, 'E5'] = dataframe_d['D5'].sum()\n",
    "dataframe_e.at[0, 'E6'] = dataframe_d['D6'].sum()\n",
    "dataframe_e.at[0, 'E7'] = dataframe_d['D7'].sum()\n",
    "dataframe_e.at[0, 'E8'] = dataframe_d['D8'].sum()\n",
    "dataframe_e.at[0, 'E9'] = dataframe_d['D9'].sum()\n",
    "dataframe_e.at[0, 'E10'] = dataframe_d['D10'].sum()\n",
    "dataframe_e.at[0, 'E11'] = dataframe_d['D11'].sum()\n",
    "dataframe_e.at[0, 'E12A'] = dataframe_d['D12A'].sum()\n",
    "dataframe_e.at[0, 'E12B'] = dataframe_d['D12B'].sum()\n",
    "dataframe_e.at[0, 'E12C'] = dataframe_d['D12C'].sum()\n",
    "dataframe_e.at[0, 'E13'] = dataframe_d['D13'].sum()\n",
    "dataframe_e.at[0, 'E14'] = dataframe_d['D14A'].sum()\n",
    "dataframe_e.at[0, 'E15'] = dataframe_d['D15'].sum()\n",
    "\n",
    "dataframe_e.to_csv(path+'/E.csv', index=False)\n",
    "with open(\"output.txt\", \"w\", encoding=\"ISO-8859-1\") as file:\n",
    "    file.write(\"\\t\".join(dataframe_a.iloc[0].astype(str)) + \"\\n\")\n",
    "    # Gruppieren nach allen B-Spalten\n",
    "    grouped = dataframe_a_b_c.groupby(list(dataframe_a_b_c.columns[dataframe_a_b_c.columns.str.startswith('B')]))\n",
    "    for _, group in grouped:\n",
    "        # Schreibe die B-Werte in die Datei\n",
    "        b_values = group.iloc[0][dataframe_a_b_c.columns.str.startswith('B')].astype(str)\n",
    "        file.write(','.join(b_values) + '\\n')\n",
    "\n",
    "        # Schreibe die C-Werte in die Datei\n",
    "        for _, row in group.iterrows():\n",
    "            c_values = row[dataframe_a_b_c.columns.str.startswith('C')].astype(str)\n",
    "            file.write(','.join(c_values) + '\\n')\n",
    "\n",
    "        # Schreibe die D-Werte in die Datei\n",
    "        b2_value = group['B2'].iloc[0]\n",
    "        d_row = dataframe_d[dataframe_d['D2'] == b2_value]\n",
    "        d_values = d_row.iloc[0].astype(str)\n",
    "        file.write(','.join(d_values) + '\\n')\n",
    "\n",
    "    # Schreibe die E-Werte in die Datei\n",
    "    for _, row in dataframe_e.iterrows():\n",
    "        e_values = row.astype(str)\n",
    "        file.write(','.join(e_values) + '\\n')\n",
    "\n",
    "        #berechne die endzeit\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86b5eeab4f19dc3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
