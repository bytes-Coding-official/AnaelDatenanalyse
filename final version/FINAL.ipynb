{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import chardet\n",
    "import pandas\n",
    "\n",
    "def read_fbp_to_csv(fbp_file_path, csv_file_path):\n",
    "    # Lesen der FBP-Datei und Schreiben der Daten in die CSV-Datei\n",
    "    with open(fbp_file_path, 'r', encoding='ISO-8859-1') as fbp_file, open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        # CSV-Writer-Objekt erstellen\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Jede Zeile der FBP-Datei lesen\n",
    "        for line in fbp_file:\n",
    "            # Zeilen aufteilen, wobei \"|\" als Trennzeichen verwendet wird\n",
    "            fields = line.strip().split(\"|\")\n",
    "            # Zeile in die CSV-Datei schreiben\n",
    "            csv_writer.writerow(fields)\n",
    "\n",
    "# FBP- und CSV-Dateipfade\n",
    "fbp_file_path = 'Auslandsdaten1.fbp'\n",
    "csv_file_path = 'Auslandsdaten1.csv'\n",
    "\n",
    "# Die ersten paar Bytes der Datei lesen, um die Kodierung zu ermitteln\n",
    "rawdata = open(fbp_file_path, \"rb\").read(10000)  # Die ersten 10.000 Bytes lesen\n",
    "result = chardet.detect(rawdata)\n",
    "charenc = result['encoding']\n",
    "# Funktion aufrufen\n",
    "read_fbp_to_csv(\"Auslandsdaten1.fbp\", \"Auslandsdaten1.csv\")\n",
    "read_fbp_to_csv(\"Auslandsdaten2.fbp\", \"Auslandsdaten2.csv\")\n",
    "#read in the csv file skip the first row of the csv file\n",
    "df = pandas.read_csv(\"Auslandsdaten1.csv\", skiprows=0, encoding=charenc)\n",
    "#drop the first 2 columns\n",
    "df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "# \n",
    "#benenne den header so um:\n",
    "# C1,C2A,C2B,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27\n",
    "df.columns = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B9\",\"B10\",\"B11\",\"B12\",\"B13\",\"B14\",\"B15\",\"B16\"]\n",
    "#speicher die datei als Ausland1neu.csv\n",
    "df.to_csv('Ausland1neu.csv', index=False)\n",
    "\n",
    "df = pandas.read_csv(\"Auslandsdaten2.csv\", skiprows=1, encoding=charenc)\n",
    "#drop the first 2 columns\n",
    "df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "#benenne den header so um:\n",
    "# C1,C2A,C2B,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,C15,C16,C17,C18,C19,C20,C21,C22,C23,C24,C25,C26,C27\n",
    "df.columns = [\"C1\",\"C2A\",\"C2B\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\",\"C10\",\"C11\",\"C12\",\"C13\",\"C14\",\"C15\",\"C16\",\"C17\", \"C18\",\"C19\",\"C20\",\"C21\",\"C22\",\"C23\",\"C24\",\"C25\",\"C26\",\"C27\"]\n",
    "#speicher die datei als Ausland1neu.csv\n",
    "df.to_csv('Ausland2neu.csv', index=False)\n",
    "\n",
    "\n",
    "# Importieren der Bibliotheken, die für die Codierung erforderlich sind\n",
    "from datetime import datetime\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "DF_merged = None\n",
    "\n",
    "\n",
    "# Funktion für B14_Pos.2\n",
    "\n",
    "def Funktion_B14_02(DF, Spalte1, Spalte2):\n",
    "    \"\"\"Diese Funktion sucht in DF-230/DSDW0230 nach den Nace-Codes \"K64\".\n",
    "      Wenn gefunden, wird in der Spalte B14 an Pos.2 \"N\" durch \"Y\" an der zweiten Stelle ersetzt.\"\"\"\n",
    "\n",
    "    DF.loc[DF[Spalte1].str.contains(\"K64.\", na=False), Spalte2] = DF[Spalte2].str[:1] + \"Y\" + DF[Spalte2].str[2:]\n",
    "\n",
    "    return DF\n",
    "\n",
    "# Funktion für B14_Pos.3\n",
    "\n",
    "def Funktion_B14_Pos03(DF1, DF2, Spalte1, Spalte2, Spalte3, Spalte4):\n",
    "    \"\"\"Diese Funktion prüft ob, die Werte \"CIN\", \"INS\", \"INSO\", \"LI\", \"NLI\", \"RI\" in der Spalte DF-3386/TPDW3386 vorhanden sind.\n",
    "       Falls ja, dann wird in der Spalte B14 an Pos.3,  \"N\" durch \"Y\" an der zweiten Stelle ersetzt.\"\"\"\n",
    "\n",
    "    global DF_merged\n",
    "    if DF_merged is None:\n",
    "        DF_merged = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "    DF_merged = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "    DF_merged.loc[DF_merged[Spalte3].isin([\"CIN\", \"INS\", \"INSO\", \"LI\",\n",
    "                                           \"NLI\", \"RI\"]), Spalte4] = DF_merged[Spalte4].str[:2] + \"Y\" + DF_merged[Spalte4].str[3:]\n",
    "\n",
    "    return DF_merged[DF1.columns]\n",
    "\n",
    "# Funktion für B14_Pos.5\n",
    "\n",
    "def Funktion_B14_05(DF1, DF2, Spalte1, Spalte2, Spalte3, Spalte4):\n",
    "    \"\"\"Diese Funktion prüft ob, die Werte \"CGOV\", \"LGOV\", \"CGOV\" in der Spalte DF-3386/TPDW3386 vorhanden sind.\n",
    "       Falls ja, dann wird in der Spalte B14 an Pos.5,  \"N\" durch \"Y\" an der fünften Stelle ersetzt.\"\"\"\n",
    "    global DF_merged\n",
    "    if DF_merged is None:\n",
    "        # Merge DF1 und DF2 um die Werte in Spalte DF-3386/TPDW3386 zu prüfen und \"N\" durch \"Y\" zu ersetzen\n",
    "        DF_merged = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "    DF_merged.loc[DF_merged[Spalte3].isin([\"CGOV\", \"LGOV\", \"SGOV\"]), Spalte4] = DF_merged[Spalte4].str[:4] + \"Y\" + DF_merged[Spalte4].str[5:]\n",
    "\n",
    "    return DF_merged[DF1.columns]\n",
    "\n",
    "\n",
    "# Funktion für B14 Pos.6\n",
    "\n",
    "def Funktion_B14_06(DF, Spalte1, Spalte2):\n",
    "    \"\"\"Diese Funktion sucht in DF-230/DSDW0230 nach den Nace-Codes, die \"K66\" enthalten.\n",
    "       Falls gefunden, wird in der Spalte B14 an Pos.6 \"N\" durch \"Y\" an der sechsten Stelle ersetzt.\"\"\"\n",
    "\n",
    "    DF.loc[DF[Spalte1].str.contains(\"K66.\", na=False), Spalte2] = DF[Spalte2].str[:5] + \"Y\" + DF[Spalte2].str[6:]\n",
    "\n",
    "    return DF\n",
    "\n",
    "# Funktion für B14 Pos.7\n",
    "\n",
    "def Funktion_B14_07(DF1, DF2, Spalte1, Spalte2, Spalte3, Spalte4):\n",
    "    \"\"\"Diese Funktion sucht in TPDW3386  nach dem Wert \"PEN\".\n",
    "       Falls gefunden, wird in der Spalte B14 an Pos.7 \"N\" durch \"Y\" an der siebten Stelle ersetzt.\"\"\"\n",
    "    # Bedingung um zu prüfen, ob \"PEN\" vorhanden ist und \"N\" durch \"Y\" ersetzen\n",
    "    #global DF_merged\n",
    "    #if DF_merged is None:\n",
    "    DF_merged = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "    DF_merged.loc[DF_merged[Spalte3] == \"PEN\", Spalte4] = DF_merged[Spalte4].str[:6] + \"Y\" + DF_merged[Spalte4].str[7:]\n",
    "\n",
    "    return DF_merged[DF1.columns]\n",
    "\n",
    "# Funktion für die Unterposition Pos.10 von B14\n",
    "\n",
    "def Funktion_B14_Pos_10(DF1, DF2, Spalte1, Spalte2, Spalte3):\n",
    "    \"\"\"Diese Funktion prüft, ob ein Kunde in der Money Laundery Entittät vorhanden ist,\n",
    "    und tauscht in der Unterposition Pos.10 von B14 \"N\" mit \"Y\", \n",
    "    falls die Prüfung positiv ist\"\"\"\n",
    "\n",
    "    # Merge der beiden Tabelle basierend auf Übereinstimmung in der Spalte1\n",
    "    DF_local_merged = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"inner\")\n",
    "    #Ersetze \"N\" durch \"Y\" in Spalte2 entsprechend des Merge\n",
    "    DF1.loc[DF_local_merged.index, Spalte3] = DF1.loc[DF_local_merged.index, Spalte3].str[:9] + \"Y\" + DF1.loc[DF_local_merged.index, Spalte3].str[10:]\n",
    "\n",
    "    return DF1\n",
    "\n",
    "\n",
    "def naechsterwert2(DF, Spalte1, Spalte2):\n",
    "    \"\"\"Diese einfache Funktion gibt dir den nächsten in einer Tabelle\"\"\"\n",
    "\n",
    "    return DF[Spalte2][DF[Spalte1].isin(DF[Spalte1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def func_neu_C4(DF1, DF2, Spalte1, Spalte2, Spalte3):\n",
    "    \"\"\" Diese Funktion.........\"\"\"\n",
    "\n",
    "    global DF_C_MERGED\n",
    "    if DF_C_MERGED is None:\n",
    "        DF_C_MERGED = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "    DF_C_MERGED[\"A\"] = \"N\"\n",
    "    DF_C_MERGED.loc[(DF_C_MERGED[Spalte3] == \"BO\"), \"A\"] = \"Y\"\n",
    "\n",
    "    Ergebnisspalte = DF_C_MERGED[\"A\"]\n",
    "\n",
    "    return Ergebnisspalte\n",
    "\n",
    "def func_neu_C5(DF1, DF2, Spalte1, Spalte2, Spalte3):\n",
    "    \"\"\"Diese Funktion......\"\"\"\n",
    "    global DF_C_MERGED\n",
    "    if DF_C_MERGED is None:\n",
    "        DF_C_MERGED = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "    DF_C_MERGED[\"B\"] = 0\n",
    "    DF_C_MERGED.loc[(DF_C_MERGED[Spalte3] == \"CR\"), \"B\"] = 1\n",
    "\n",
    "    # Group data\n",
    "    DF_grouped = DF_C_MERGED.groupby(Spalte1)[\"B\"].sum().reset_index()\n",
    "\n",
    "    return DF_grouped[\"B\"]\n",
    "\n",
    "\n",
    "def Funktion_C15(DF1, DF2, Spalte1, Spalte2, Spalte3, Spalte4):\n",
    "    \"\"\"Diese Funktion .....\"\"\"\n",
    "\n",
    "    merged = DF1.merge(DF2, left_on=Spalte1, right_on=Spalte2, how=\"left\")\n",
    "\n",
    "    condition = merged[Spalte3] == \"0\"\n",
    "\n",
    "    DF1[Spalte4] = \"N\"\n",
    "    DF1.loc[condition, Spalte4] = \"Y\"\n",
    "\n",
    "    return DF1[Spalte4]\n",
    "\n",
    "#\"../files\n",
    "\n",
    "path = \"../../DE1D_2023_06_13\"\n",
    "\n",
    "\n",
    "# Path zur Directory, wo alle einzulesenden Dateien vorhanden sind\n",
    "\n",
    "##########################################-I Einlesen Der Daten-####################################################################################\n",
    "# Einlesen der Business Partner und Business Partner act in Liability und die Money Laundery-Entitäten. \n",
    "# Dateien, die wir für den Aufbau des B-Satzes benötigen\n",
    "# Nach dem Einlesen muss entsprechend der Entitäten die neue Spalte KYDW0007, KYDWR50880 und KYDWR5469O erzeugt werden,  entsprechend den Testdaten\n",
    "# Z.B KYDW0007 ist eine Kombination der Spalten KDW0007 und KDW0007O\n",
    "\n",
    "# 1. Einlesen der Business Partner-Entität\n",
    "\n",
    "\n",
    "DF_BP = pd.read_csv(path + \"/BPART.csv\", sep=\"\\t\", skiprows=9)\n",
    "# KYDW0007 wird durch eine \"Join\" der Spalten KDW0007 und KDW0007O. Die Spalte wird am Ende des Dataframes hinzugefügt \n",
    "DF_BP[\"KYDW0007\"] = DF_BP[[\"KDW0007O\", \"KDW0007\"]].astype(str).agg(\"/\".join, axis=1)\n",
    "# Die neue KYDW0007-Spalte wird am Anfang des Dataframes hingefügt \n",
    "first_column = DF_BP.pop(\"KYDW0007\")\n",
    "DF_BP.insert(2, \"KYDW0007O\", first_column)\n",
    "# Das neue Dataframe wird ausgefürt \n",
    "\n",
    "\n",
    "with open(path + \"/Datei_TPDW3386.csv\", \"rb\") as file:\n",
    "    enc = chardet.detect(file.read())\n",
    "\n",
    "DF_3386 = pd.read_csv(path + \"/Datei_TPDW3386.csv\", sep=\";\", encoding=enc[\"encoding\"])\n",
    "\n",
    "\n",
    "# Werte der Spalte TPGC3386\n",
    "DF_3386[\"TPGC3386\"].values\n",
    "\n",
    "# Einfügen der Spalte \"TPGC3386\" als \"TPDW3386\" in DF_BP\n",
    "\n",
    "DF_BP[\"TPDW3386\"] = DF_3386[\"TPGC3386\"]\n",
    "\n",
    "# 2.Einlesen der Business Partner act in Liability-Entität \n",
    "\n",
    "\n",
    "DF_BPact = pd.read_csv(path + \"/BPART_Act.csv\", sep=\"\\t\", skiprows=9)\n",
    "# KYDWR5088O wird durch eine \"Join\" der Spalten KDWR5088 und KDWR5088O. Die Spalte wird am Ende des Dataframes hinzugefügt \n",
    "DF_BPact[\"KYDWR5088\"] = DF_BPact[[\"KDWR5088O\", \"KDWR5088\"]].astype(str).agg(\"/\".join, axis=1)\n",
    "# Die neue KYDWR5088O-Spalte wird am Anfang des Dataframes hingefügt \n",
    "Second_column = DF_BPact.pop(\"KYDWR5088\")\n",
    "DF_BPact.insert(2, \"KYDWR5088O\", Second_column)\n",
    "# Das neue Dataframe wird ausgefürt \n",
    "\n",
    "# Merge Business Partner und Business Partner act in Liabil\n",
    "DF_merged2 = DF_BPact.join(DF_BP, lsuffix=\"KDWR5088O\", rsuffix=\"KYDW0007\")\n",
    "# Erstelle die Spalte der Kundennummern mit \"CR\"\n",
    "DF_merged2 = DF_BPact.join(DF_BP, lsuffix=\"KDWR5088O\", rsuffix=\"KYDW0007\")\n",
    "DF_merged2.loc[DF_merged2[\"TPDW5090\"] == \"CR\"][\"KYDW0007O\"]\n",
    "#3.Einlesen der Money laundering Entität \n",
    "DF_MONLA = pd.read_csv(path + \"/MONEYLA.csv\", sep=\"\\t\", skiprows=9)\n",
    "DF_MONLA[\"KYDWR5469\"] = DF_MONLA[[\"KDWR5469O\", \"KDWR5469\"]].astype(str).agg(\"/\".join, axis=1)\n",
    "neue_Spalte = DF_MONLA.pop(\"KYDWR5469\")\n",
    "DF_MONLA.insert(2, \"KYDWR5469O\", neue_Spalte)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################+++++++++ II. Bau der Sätze +++++##################################################\n",
    "A_Satz = pd.DataFrame([[''] * 10], columns=['A{}'.format(i) for i in range(1, 11)])\n",
    "A_Satz[\"A1\"] = 'A'\n",
    "A_Satz[\"A2\"] = '165'\n",
    "A_Satz[\"A3\"] = '10'\n",
    "A_Satz[\"A4\"] = 100000.00\n",
    "A_Satz[\"A5\"] = 0.00\n",
    "A_Satz[\"A6A\"] = 1330170000.00\n",
    "A_Satz[\"A6B\"] = 5000000\n",
    "A_Satz[\"A6C\"] = 50000000\n",
    "A_Satz[\"A7\"] = 1392530000.00\n",
    "A_Satz[\"A8\"] = '00000000'\n",
    "A_Satz[\"A9A\"] = 0.00\n",
    "A_Satz[\"A9B\"] = 0.00\n",
    "A_Satz[\"A9C\"] = 0.00\n",
    "A_Satz[\"A10\"] = '00000000'\n",
    "\n",
    "# Die Spalten des A_Satzes werden in die gewünscht Reihenfolge sortiert\n",
    "\n",
    "A_Satz.columns = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A6A\",\n",
    "                  \"A6B\", \"A6C\", \"A7\", \"A8\", \"A9\", \"A9A\", \"A9B\", \"A9C\", \"A10\"]\n",
    "\n",
    "# A_Satz wird ausgegeben\n",
    "\n",
    "###################################+++++++++ II. Bau der Sätze +++++##################################################\n",
    "A_Satz = pd.DataFrame([[''] * 10], columns=['A{}'.format(i) for i in range(1, 11)])\n",
    "A_Satz[\"A1\"] = 'A'\n",
    "A_Satz[\"A2\"] = '165'\n",
    "A_Satz[\"A3\"] = '10'\n",
    "A_Satz[\"A4\"] = 100000.00\n",
    "A_Satz[\"A5\"] = 0.00\n",
    "A_Satz[\"A6A\"] = 1330170000.00\n",
    "A_Satz[\"A6B\"] = 5000000\n",
    "A_Satz[\"A6C\"] = 50000000\n",
    "A_Satz[\"A7\"] = 1392530000.00\n",
    "A_Satz[\"A8\"] = '00000000'\n",
    "A_Satz[\"A9A\"] = 0.00\n",
    "A_Satz[\"A9B\"] = 0.00\n",
    "A_Satz[\"A9C\"] = 0.00\n",
    "A_Satz[\"A10\"] = '00000000'\n",
    "\n",
    "# Die Spalten des A_Satzes werden in die gewünscht Reihenfolge sortiert\n",
    "\n",
    "A_Satz.columns = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A6A\",\n",
    "                  \"A6B\", \"A6C\", \"A7\", \"A8\", \"A9\", \"A9A\", \"A9B\", \"A9C\", \"A10\"]\n",
    "\n",
    "# A_Satz wird ausgegeben\n",
    "\n",
    "B_Satz2 = pd.DataFrame([[''] * 16], index=range(1, 1460612), columns=[\"B{}\".format(i) for i in range(1, 17)])\n",
    "\n",
    "BPART_MERGE = B_Satz2.merge(DF_BP, left_on=\"B2\", right_on=\"KYDW0007O\", how=\"inner\")\n",
    "\n",
    "\n",
    "def Funktion_B16(row):\n",
    "    if row[\"TPDW0235\"] == \"I-NP\":\n",
    "        return \"10\"\n",
    "    elif all(x == \"N\" for x in row[\"B14\"]):\n",
    "        return \"13\"\n",
    "    elif row[\"TPDW5483\"] == \"Y\":\n",
    "        return \"20\"\n",
    "    else:\n",
    "        return \"90\"\n",
    "\n",
    "B_Satz2[\"B1\"] = \"B\"\n",
    "B_Satz2[\"B2\"] = DF_merged2.loc[DF_merged2[\"TPDW5090\"] == \"CR\"][\"KYDW0007O\"]\n",
    "B_Satz2[\"B3\"] = DF_BP[\"DSDW0010\"]\n",
    "B_Satz2[\"B4\"] = DF_BP[\"TPDW4438\"]\n",
    "B_Satz2[\"B5\"] = \"\"  # LEER lassen\n",
    "B_Satz2[\"B6\"] = DF_BP[\"TPDW4438\"]\n",
    "B_Satz2[\"B7\"] = DF_BP[\"DSDW3702\"]\n",
    "B_Satz2['B8'] = \"\"\n",
    "B_Satz2[\"B9\"] = DF_BP[\"DSDW0013\"]\n",
    "B_Satz2[\"B10\"] = DF_BP[\"DSDW0014\"]\n",
    "B_Satz2[\"B11\"] = DF_BP[\"TPDW0012\"]\n",
    "B_Satz2[\"B12\"] = DF_BP[\"DTDW4315\"]\n",
    "B_Satz2[\"B13\"] = DF_BP[\"DSDW0230\"]\n",
    "B_Satz2[\"B14\"] = \"N\" * 50\n",
    "B_Satz2[\"B15\"] = \"\"\n",
    "B_Satz2[\"B16\"] = B_Satz2.apply(Funktion_B16, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# 4 Einlesen der Liability Entität für den Bau des C-Satzes\n",
    "\n",
    "DF_Liab = pd.read_csv(path + \"/PLIAB Kopie.csv\", sep=\"\\t\", skiprows=9, decimal=\",\")\n",
    "\n",
    "\n",
    "# 5 Einlesen der PRODUCT-Entität für die Bestimmung der Produktnamen in C6\n",
    "\n",
    "with open(path + \"/PRODUCT.csv\", \"rb\") as file:\n",
    "    enc = chardet.detect(file.read())\n",
    "DF_PRO = pd.read_csv(path + \"/PRODUCT.csv\", sep=\";\", skiprows=9, encoding=enc[\"encoding\"])\n",
    "\n",
    "\n",
    "BP_CANLA = pd.read_csv(path + \"/BP_CANLA.csv\", sep=\"\\t\", skiprows=9, decimal=\".\")\n",
    "B_Satz2 = Funktion_B14_02(B_Satz2, \"B13\", \"B14\")\n",
    "B_Satz2 = Funktion_B14_Pos03(B_Satz2, DF_BP, \"B2\", \"KYDW0007O\", \"TPDW3386\", \"B14\")\n",
    "\n",
    "# Für die Unterposition B14_Pos.04 schreiben wir den festen Wert \"N\"\n",
    "\n",
    "# Aufruf der Funktion für Position B14_Pos.05.\"CGOV\", \"LGOV\" und \"SGOV\" werden in TPDW3386 geprüft\n",
    "# und entsprechend \"N\" durch \"Y\" an der 5. Stelle ersetzt\n",
    "\n",
    "B_Satz2 = Funktion_B14_05(B_Satz2, DF_BP, \"B2\", \"KYDW0007O\", \"TPDW3386\", \"B14\")\n",
    "\n",
    "# Aufruf der Funktion für Position B14_Pos.06. String, die \"K66.\" werden in DSDW0230 geprüft\n",
    "# und entsprechend \"N\" durch \"Y\" an der 6. Stelle ersetzt\n",
    "\n",
    "B_Satz2 = Funktion_B14_06(B_Satz2, \"B13\", \"B14\")\n",
    "\n",
    "\n",
    "# Aufruf der Funktion für Position B14_Pos.07. String, die \"PEN\" werden in \"TPDW3386\" geprüft\n",
    "# und entsprechend \"N\" durch \"Y\" an der 7. Stelle ersetzt\n",
    "\n",
    "B_Satz2 = Funktion_B14_07(B_Satz2, DF_BP, \"B2\", \"KYDW0007O\", \"TPDW3386\", \"B14\")\n",
    "\n",
    "\n",
    "# Aufruf der Funktion für Position B14_Pos.10. String, die \"PEN\" werden in \"TPDW3386\" geprüft\n",
    "# und entsprechend \"N\" durch \"Y\" an der 10. Stelle ersetzt\n",
    "\n",
    "B_Satz2 = Funktion_B14_Pos_10(B_Satz2, DF_MONLA, \"B2\", \"KYDWR5469O\", \"B14\")\n",
    "\n",
    "# Prüfen der Werte in B14\n",
    "\n",
    "B_Satz2.B14.value_counts()\n",
    "\n",
    "DF1 = pd.DataFrame(B_Satz2)\n",
    "DF1.to_csv(path+\"/B_Satz.csv\")\n",
    "DF1 = DF1.tail(-1)\n",
    "# A_Satz wird noch als DataFrame eingelesen und alle Spaltennamen werden entfernt\n",
    "\n",
    "DF2 = pd.DataFrame(A_Satz)\n",
    "DF2.to_csv(path+\"/A_Satz.csv\")\n",
    "DF2 = DF2.tail(-1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Definiere ein neuen DataFrame, der die Spalten von DF1 und DF2 hat.\n",
    "# Hier bekommt DF2 einen neuen index so dass, die Spalten von DF2 in der gleichen Reihenfolge wie die Spalte von DF1 sind\n",
    "# Das heisst, dass neue Spalten mit None gefüllt werden in DF2 eingefügt\n",
    "DF_GroßerSatz = pd.concat([DF2, DF1.reindex(columns=DF1.columns)], ignore_index=True)\n",
    "# Entferne die erste Spalte\n",
    "DF_GroßerSatz = DF_GroßerSatz.iloc[:, 1:]\n",
    "\n",
    "# DF_GroßerSatz enthält jetzt die Daten aus beiden DataFrames, wobei fehlende Spalten in DF2 auf None gesetzt sind\n",
    "DF_merg3 = DF_Liab.merge(DF_PRO, left_on=\"KDWR5097\", right_on=\"KMDPRODID\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "# Merge der Cancellation- und Liability-Entität für C26\n",
    "\n",
    "DF_C_MERGED = None\n",
    "C_liab = pd.DataFrame([[''] * 27], index=range(0, 1460610), columns=[\"C{}\".format(i) for i in range(1, 28)])\n",
    "C_liab[\"C1\"] = \"C\"\n",
    "C_liab[\"C2B\"] = DF_Liab[\"KDW5082\"]\n",
    "C_liab.dropna(subset=\"C2B\", inplace=True)\n",
    "DF = DF_BPact[DF_BPact[\"TPDW5090\"] == \"CR\"]\n",
    "DF = DF[[\"KDWR5089\", \"KYDWR5088O\"]]\n",
    "C_liab = C_liab.merge(DF, left_on=\"C2B\", right_on=\"KDWR5089\")  #war: left soll inner\n",
    "DF_merged10 = DF_Liab.merge(BP_CANLA, left_on=\"KDW5082\", right_on=\"KDWR5000\", how=\"left\")  #muss left\n",
    "\n",
    "C_liab[\"C4\"] = func_neu_C4(DF_Liab, DF_BPact, \"KDW5082\", \"KDWR5089\", \"TPDW5090\")\n",
    "C_liab[\"C5\"] = func_neu_C5(DF_Liab, DF_BPact, \"KDW5082\", \"KDWR5089\", \"TPDW5090\")\n",
    "C_liab[\"C6\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"DTDW5113\").apply(lambda x: str(int(x)) if not pd.isnull(x) else x)  # [\"DTDW5113\" for \"DTDW5113\" in DF_Liab.set_index(\"KDW5082\").columns]  # DF_Liab[\"DTDW5113\"].sort_values(\"KDW5082\")                                        #S-Verweis: Suche aus PLIABA den Vertrag (KYDW5082) und das dazugehörige Datum DTDW5113 und schreibe es in C6\n",
    "C_liab[\"C7\"] = naechsterwert2(DF_merg3, \"KDW5082\", \"DSMDPRODN\")  # Sverweis(DF_Liab,DF_PRO, \"KDW5082\", \"KDWR5097\", DF_Liab, DF_PRO,\"KMDPRODID\", \"TPMDPPRCD\", \"KDW5082\" )\n",
    "C_liab[\"C8\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"UCDW5105\")\n",
    "C_liab[\"C9\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"ATDW5105\")  # naechsterwert2(DF_Liab, \"KDW5082\", \"ATDW5105\").apply(lambda x:-x)                                                            # DF_Liab[DF_Liab[\"KDW5082\"].isin(DF_Liab[\"KDW5082\"])]DF_Liab[\"ATDW5105\"].apply(lambda x: -x if x > 0 else x)\n",
    "C_liab[\"C10\"] = \"{:,.5f}\".format(100000 / 100000)  # 1.00000                                                            #naechsterwert2(DF_Liab, \"KDW5082\", \"TPDW5086\")\n",
    "C_liab[\"C11\"] = C_liab[\"C9\"].astype(float) * C_liab[\"C10\"].astype(float)\n",
    "C_liab[\"C12\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"QUDW5537\").astype(str) + DF_Liab[\"UCDW5537\"]\n",
    "C_liab[\"C13\"] = \"X\"\n",
    "C_liab[\"C14\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"DTDW5084\")\n",
    "C_liab[\"C15\"] = Funktion_C15(C_liab, DF_Liab, \"C2B\", \"KDW5082\", \"QUDW5182\", \"C15\")\n",
    "C_liab[\"C16\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"TPDW5562\")\n",
    "C_liab[\"C17\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"ATDW5107\")\n",
    "C_liab[\"C18\"] = C_liab[\"C10\"].astype(float) * C_liab[\"C17\"].astype(float)\n",
    "C_liab[\"C19\"] = C_liab[\"C18\"].astype(float) + C_liab[\"C11\"].astype(float)  # C_liab[\"C11\"] + C_liab[\"C18\"]\n",
    "C_liab[\"C20\"] = \"N\" * 50  # C_Pos[[\"C_Pos{}\".format(i) for i in range(1, 51)]].astype(str).agg(\"\".join, axis = 1)\n",
    "C_liab[\"C21\"] = \"N\" * 50  # C_Pos[[\"C_Pos{}\".format(i) for i in range(1, 51)]].astype(str).agg(\"\".join, axis = 1)\n",
    "C_liab[\"C22\"] = \"DE\"\n",
    "C_liab[\"C23\"] = \"\"\n",
    "C_liab[\"C25\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"QUDW5094\")\n",
    "C_liab.rename(columns={\"KYDWR5088O\": \"C2A\"}, inplace=True)\n",
    "\n",
    "def set_C24_value(row):\n",
    "    #return the value in column \"DTDW5484\" related to the corresponding value of C2B in DF_Liab in the column \"KDW5082\"\n",
    "    return DF_Liab.loc[DF_Liab[\"KDW5082\"] == row[\"C2B\"], \"DTDW5484\"].values[0]\n",
    "\n",
    "\n",
    "C_liab[\"C24\"] = C_liab.apply(set_C24_value, axis=1)\n",
    "\n",
    "def set_C26_value(row):\n",
    "    if row[\"C20\"][44] == \"Y\":\n",
    "        #get the value from DF CANELA where KDWR5000 = C2B\n",
    "        return BP_CANLA.loc(row[\"C2B\"], \"ATDW5156\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "C_liab[\"C26\"] = C_liab.apply(set_C26_value, axis=1)\n",
    "\n",
    "def set_C27_value(row):\n",
    "    # Wert: 90 - Ohne Ausschluss\n",
    "\n",
    "    #finde die reihe aus B wo B2 = C2A\n",
    "    #wenn B14 = N und C20 = N dann 90\n",
    "    b_row_14 = B_Satz2.loc[B_Satz2['B2'] == row['C2A'], \"B14\"]\n",
    "    if all(b_row_14 == 'N') and all(c_values == \"N\" for c_values in row[\"C20\"]):\n",
    "        return '90'\n",
    "\n",
    "    # Wert: 01 - Ausschluss nur nach EinSiG\n",
    "    if any(b_row_14[0:15].count(\"Y\") > 0) and all(c_values == \"N\" for c_values in b_row_14[15:50]) and all(c == 'N' for c in row['C20'][10:50]):\n",
    "        return '01'\n",
    "    elif row['C20'][0:10].count('Y') > 0 and all(c == 'N' for c in row['C20'][10:50]) and all(c == 'N' for c in b_row_14[15:50]):\n",
    "        # do something\n",
    "        return '01'\n",
    "\n",
    "    # Wert: 20 - Ausschluss nur nach ESF-Statut\n",
    "    if any(b_row_14[30:50].count(\"Y\") > 0) and all(c == \"N\" for c in b_row_14[0:30]) and all(c == \"N\" for c in row['C20'][0:30]):\n",
    "        return '20'\n",
    "    elif any(row['C20'][30:50].count(\"Y\") > 0) and all(c == 'N' for c in row['C20'][0:30]) and all(c == 'N' for c in b_row_14[0:30]):\n",
    "        return '20'\n",
    "\n",
    "    # Wert: 11 - Ausschluss \"Bagatellgrenze\" nach EinSiG und ESF-Statut\n",
    "    if all(c == 'N' for c in row['C20'][1:49]) and row['C20'][49] == 'Y':\n",
    "        return '11'\n",
    "\n",
    "    # Wert: 10 - Ausschluss nach EinSiG und ESF-Statut (alle anderen Fälle)\n",
    "    return '10'\n",
    "\n",
    "\n",
    "# Anwenden der Funktion auf den DataFrame\n",
    "C_liab['C27'] = C_liab.apply(set_C27_value, axis=1)\n",
    "C_liab['C27']\n",
    "\n",
    "C_Satz = C_liab[[\"C1\", \"C2A\", \"C2B\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \"C9\", \"C10\", \"C11\", \"C12\", \"C13\",\n",
    "                 \"C14\", \"C15\", \"C16\", \"C17\", \"C18\", \"C19\", \"C20\", \"C21\", \"C22\", \"C23\", \"C24\", \"C25\", \"C26\", \"C27\"]]\n",
    "# gewünschte C-Satz ausgeben\n",
    "Tab2 = C_Satz.groupby(\"C2B\")\n",
    "Tab3 = Tab2[\"C2A\"].count().reset_index(name=\"Anzahl Vertrag pro Kunde\").sort_values([\"Anzahl Vertrag pro Kunde\"], ascending=False)\n",
    "\n",
    "Tab4 = Tab3.loc[Tab3[\"Anzahl Vertrag pro Kunde\"] == 1]  #hier sonst auf 2 ändern\n",
    "Tab5 = C_Satz.loc[C_Satz[\"C2B\"].isin(Tab4[\"C2B\"])]\n",
    "\n",
    "Tab6 = Tab5.groupby(\"C2B\")[\"C2A\"].apply(list).reset_index(name=\"Kunden_Nummern\")\n",
    "\n",
    "Tab7 = Tab6[\"C2B\"].tolist()\n",
    "Num = Tab7[0]\n",
    "Tab8 = C_Satz.loc[C_Satz[\"C2B\"] == Num]\n",
    "#\n",
    "Tab9 = Tab8.groupby(\"C2A\")[\"C2B\"].apply(list).reset_index(name=\"Vertrag_Nummern\")\n",
    "\n",
    "x = C_Satz.loc[(C_Satz[\"C2A\"] == 'DE1-ZGP/13233006')]\n",
    "################++++++ Definition des C-Satzes(Contract) +++++##############\n",
    "C_Satz.to_csv(path+\"/C.csv\", index=False)\n",
    "#drop all rows where B2 is empty\n",
    "B_Satz2.dropna(subset=[\"B2\", \"B3\"], inplace=True)\n",
    "B_Satz2.to_csv(path+\"/B.csv\", index=False)\n",
    "A_Satz.to_csv(path+\"/A.csv\", index=False)\n",
    "import time\n",
    "t_0 = time.time()\n",
    "\n",
    "DF_CONTR = pd.read_csv(path + \"/CONTR.csv\", sep=\"\\t\", skiprows=9, decimal=\".\")\n",
    "DF_merg6 = DF_CONTR.merge(DF_PRO, left_on=\"KDW0046A\", right_on=\"KMDPRODID\", how=\"left\")  #????\n",
    "\n",
    "DF_merg6#\n",
    "C_CONT = pd.DataFrame([[''] * 27], index=range(0, 1460610), columns=[\"C{}\".format(i) for i in range(1, 28)])\n",
    "C_CONT[\"C1\"] = \"C\"\n",
    "C_CONT[\"C2B\"] = DF_CONTR[\"KDW0034\"]\n",
    "C_CONT.dropna(subset=\"C2B\", inplace=True)\n",
    "DF = DF_BPact[DF_BPact[\"TPDW5090\"] == \"DB\"]\n",
    "DF = DF[[\"KDWR5089\", \"KDWR5088\"]]\n",
    "###++++ Definition des C_Satzes für die Contract Entität +++++###########\n",
    "C_CONT = C_CONT.merge(DF, left_on=\"C2B\", right_on=\"KDWR5089\", how=\"inner\")\n",
    "\n",
    "#rename KDWR5088 to C2A\n",
    "\n",
    "C_CONT.rename(columns={\"KDWR5088\": \"C2A\"}, inplace=True)\n",
    "\n",
    "C_CONT[\"C4\"] = \"N\"\n",
    "C_CONT[\"C5\"] = func_neu_C5(DF_Liab, DF_BPact, \"KDW5082\", \"KDWR5089\", \"TPDW5090\")\n",
    "C_CONT[\"C6\"] = naechsterwert2(DF_CONTR, \"KDW0034\", \"DTDW0039\")  # [\"DTDW5113\" for \"DTDW5113\" in DF_Liab.set_index(\"KDW5082\").columns]  # DF_Liab[\"DTDW5113\"].sort_values(\"KDW5082\")                                        #S-Verweis: Suche aus PLIABA den Vertrag (KYDW5082) und das dazugehörige Datum DTDW5113 und schreibe es in C6\n",
    "C_CONT[\"C7\"] = naechsterwert2(DF_merg6, \"KDW0034\", \"DSMDPRODN\")  # Sverweis(DF_Liab,DF_PRO, \"KDW5082\", \"KDWR5097\", DF_Liab, DF_PRO,\"KMDPRODID\", \"TPMDPPRCD\", \"KDW5082\" )\n",
    "C_CONT[\"C8\"] = naechsterwert2(DF_CONTR, \"KDW0034\", \"UDW3567\")\n",
    "C_CONT[\"C9\"] = naechsterwert2(DF_CONTR, \"KDW0034\", \"ADW3567\").apply(lambda string: string.replace(\",\", \".\")).astype(float).apply(lambda x: -x if x != 0 else x)  # DF_Liab[DF_Liab[\"KDW5082\"].isin(DF_Liab[\"KDW5082\"])]DF_Liab[\"ATDW5105\"].apply(lambda x: -x if x > 0 else x)\n",
    "C_CONT[\"C10\"] = \"{:,.5f}\".format(100000 / 100000)  # naechsterwert2(DF_CONTR, \"KDW5082\", \"TPDW5086\")\n",
    "C_CONT[\"C11\"] = C_liab[\"C9\"].astype(float) * C_liab[\"C10\"].astype(float)\n",
    "C_CONT[\"C12\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"QUDW5537\").astype(str) + DF_Liab[\"UCDW5537\"]\n",
    "C_CONT[\"C13\"] = \"X\"\n",
    "C_CONT[\"C14\"] = \"X\"  # naechsterwert2(DF_CONTR, \"KDW5082\", \"DTDW5084\")\n",
    "C_CONT[\"C15\"] = \"X\"\n",
    "C_CONT[\"C16\"] = \"X\"  # naechsterwert2(DF_CONTR, \"KDW5082\", \"TPDW5562\")\n",
    "C_CONT[\"C17\"] = naechsterwert2(DF_Liab, \"KDW5082\", \"ATDW5107\").apply(lambda x: -x if x != 0 else x)\n",
    "C_CONT[\"C18\"] = \"X\"\n",
    "C_CONT[\"C19\"] = \"X\"\n",
    "C_CONT[\"C20\"] = \"N\" * 50  # C_Pos[[\"C_Pos{}\".format(i) for i in range(1, 51)]].astype(str).agg(\"\".join, axis = 1)                                                                    # C_Pos[[\"C_Pos{}\".format(i) for i in range(1, 51)]].astype(str).agg(\"\".join, axis = 1)\n",
    "C_CONT[\"C21\"] = \"N\" * 50  # C_Pos[[\"C_Pos{}\".format(i) for i in range(1, 51)]].astype(str).agg(\"\".join, axis = 1)\n",
    "C_CONT[\"C22\"] = \"DE\"\n",
    "C_CONT[\"C23\"] = \"\"\n",
    "C_CONT[\"C24\"] = \"X\"\n",
    "C_CONT[\"C25\"] = \"X\"\n",
    "C_CONT[\"C26\"] = \"X\"\n",
    "C_CONT[\"C27\"] = \"X\"\n",
    "def C_20_Pos12(row):\n",
    "    temp_list = list(row[\"C20\"])\n",
    "    temp_list[11] = \"Y\" if row[\"C20\"][1] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list)\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos12, axis=1)\n",
    "\n",
    "def C_20_Pos13(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list = list(row[\"C20\"])\n",
    "    temp_list[12] = \"Y\" if B_Satz2Row[\"B14\"][1] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list)\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos13, axis=1)\n",
    "def C_20_Pos14(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list_13 = list(row[\"C20\"])\n",
    "    temp_list_13[13] = \"Y\" if B_Satz2Row[\"B14\"][4] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list_13)\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos14, axis=1)\n",
    "def C_20_Pos15(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list_14 = list(row[\"C20\"])\n",
    "    temp_list_14[14] = \"Y\" if B_Satz2Row[\"B14\"][5] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list_14)\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos15, axis=1)\n",
    "\n",
    "def C_20_Pos16(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list_15 = list(row[\"C20\"])\n",
    "    temp_list_15[15] = \"Y\" if B_Satz2Row[\"B14\"][9] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list_15)\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos16, axis=1)\n",
    "#LAUT ANAEL WEGLASSEN!\n",
    "def C_20_Pos31(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    row[\"C20\"][30] = \"Y\" if B_Satz2Row[\"B14\"][9] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "\n",
    "#LAUT ANAEL WEGLASSEN!\n",
    "def C_20_Pos32(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    row[\"C20\"][31] = \"Y\" if B_Satz2Row[\"B14\"][9] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "def C_20_Pos33(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list_32 = list(row[\"C20\"])\n",
    "    temp_list_32[32] = \"Y\" if B_Satz2Row[\"B16\"] >= 20 and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list_32)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos33, axis=1)\n",
    "def C_20_Pos34(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    if B_Satz2Row[\"B16\"] >= 20:\n",
    "        #dateformat = dd-mm-yyyy\n",
    "        date_start = datetime.strptime(row[\"C6\"], \"%d%m%Y\")\n",
    "        date_end = datetime.strptime(row[\"C14\"], \"%d%m%Y\")\n",
    "        temp_list_33 = list(row[\"C20\"])\n",
    "        temp_list_33[33] = \"Y\" if row[\"C25\"] > 18 and date_start < datetime.strptime(\"01-01-2020\", \"%d-%m-%Y\") and date_end > datetime.strptime(\"31-12-2019\", \"%d-%m-%Y\") else \"N\"\n",
    "        return ''.join(temp_list_33)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos34, axis=1)\n",
    "def C_20_Pos35(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    if B_Satz2Row[\"B16\"] >= 20:\n",
    "        #dateformat = dd-mm-yyyy\n",
    "        date_start = datetime.strptime(row[\"C6\"], \"%d%m%Y\")\n",
    "        date_end = datetime.strptime(row[\"C14\"], \"%d%m%Y\")\n",
    "        temp_list_34 = list(row[\"C20\"])\n",
    "        temp_list_34[34] = \"Y\" if row[\"C25\"] > 18 and date_start > datetime.strptime(\"31-12-2019\", \"%d-%m-%Y\") and date_start <= datetime.strptime(\"31-12-2022\", \"%d-%m-%Y\") else \"N\"\n",
    "        return ''.join(temp_list_34)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos35, axis=1)\n",
    "def C_20_Pos36(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    if B_Satz2Row[\"B16\"] >= 20:\n",
    "        #dateformat = dd-mm-yyyy\n",
    "        date_start = datetime.strptime(row[\"C6\"], \"%d%m%Y\")\n",
    "        date_end = datetime.strptime(row[\"C14\"], \"%d%m%Y\")\n",
    "        temp_list_35 = list(row[\"C20\"])\n",
    "        temp_list_35[35] = \"Y\" if (row[\"C25\"] is None or row[\"C25\"] == \"\") and date_start < datetime.strptime(\"01-01-2020\", \"%d-%m-%Y\") and date_end > datetime.strptime(\"31-12-2019\", \"%d-%m-%Y\") else \"N\"\n",
    "    return ''.join(temp_list_35)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos36, axis=1)\n",
    "def C_20_Pos37(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    if B_Satz2Row[\"B16\"] >= 20:\n",
    "        #dateformat = dd-mm-yyyy\n",
    "        date_start = datetime.strptime(row[\"C6\"], \"%d%m%Y\")\n",
    "        temp_list_36 = list(row[\"C20\"])\n",
    "        temp_list_36[36] = \"Y\" if (row[\"C25\"] is None or row[\"C25\"] == \"\") and date_start > datetime.strptime(\"31-12-2019\", \"%d-%m-%Y\") and date_start <= datetime.strptime(\"31-12-2022\", \"%d-%m-%Y\") else \"N\"\n",
    "        return ''.join(temp_list_36)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos37, axis=1)\n",
    "def C_20_Pos43(row):\n",
    "    if row[\"C21\"][19] == \"N\":\n",
    "        #dateformat = dd-mm-yyyy\n",
    "\n",
    "        temp_list_42 = list(row[\"C20\"])\n",
    "        temp_list_42[42] = \"Y\" if (row[\"C22\"] != \"\" and row[\"C22\"] is not None and row[\"C22\"] != \"DE\") or (row[\"C23\"] != \"\" and row[\"C23\"] is not None) else \"N\"\n",
    "        return ''.join(temp_list_42)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos43, axis=1)\n",
    "def C_20_Pos44(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    if B_Satz2Row[\"B16\"] >= 20 and row[\"C21\"][19] == \"N\":\n",
    "        temp_list_43 = list(row[\"C20\"])\n",
    "        temp_list_43[43] = \"Y\" if row[\"C25\"] > 12 else \"N\"\n",
    "        return ''.join(temp_list_43)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos44, axis=1)\n",
    "def C_20_Pos45(row):\n",
    "    B_Satz2Row = B_Satz2.loc[B_Satz2[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    if B_Satz2Row[\"B16\"] >= 20 and row[\"C21\"][19] == \"N\":\n",
    "        temp_list_44 = list(row[\"C20\"])\n",
    "        temp_list_44[44] = \"Y\" if row[\"C25\"] is None or row[\"C25\"] == \"\" else \"N\"\n",
    "        return ''.join(temp_list_44)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos45, axis=1)\n",
    "def C_20_Pos50(row):\n",
    "    temp_list_49 = list(row[\"C20\"])\n",
    "    temp_list_49[49] = \"Y\" if row[\"C19\"] < 20 else \"N\"\n",
    "    return ''.join(temp_list_49)\n",
    "\n",
    "\n",
    "C_Satz[\"C20\"] = C_Satz.apply(C_20_Pos50, axis=1)\n",
    "\n",
    "C_CONT = C_CONT[[\"C1\", \"C2A\", \"C2B\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \"C9\", \"C10\", \"C11\", \"C12\", \"C13\",\n",
    "                 \"C14\", \"C15\", \"C16\", \"C17\", \"C18\", \"C19\", \"C20\", \"C21\", \"C22\", \"C23\", \"C24\", \"C25\", \"C26\", \"C27\"]]\n",
    "# gewünschte C-Satz ausgeben\n",
    "# füge die daten von C_Satz über die von C_CONT an\n",
    "C_neu = pd.concat([C_Satz, C_CONT], ignore_index=True)\n",
    "C_neu.to_csv(path+\"/C.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "#berechne die aktuelle startzeit\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#check if a A.csv, B.csv, C.csv, D.csv und E.csv datei exisieren wenn ja dann lass sie wenn nein erstell sie neu\n",
    "path = \"../../DE1D_2023_06_13\"\n",
    "\n",
    "with open(path+\"/D.csv\", \"w\") as file:\n",
    "    file.write(\"D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12A,D12B,D12C,D13,D14A,D15\\n\")\n",
    "\n",
    "with open(path+\"/E.csv\", \"w\") as file:\n",
    "    file.write(\"E1,E3,E4,E5,E6,E7,E8,E9,E10,E11,E12A,E12B,E12C,E13,E14,E15\\n\")\n",
    "\n",
    "dataframe_a = pandas.read_csv(path+\"/A.csv\", sep=',', header=0)\n",
    "dataframe_b = pandas.read_csv(path+\"/Ausland1neu.csv\", sep=',', header=0) #Ausland1neu -> B\n",
    "dataframe_c = pandas.read_csv(path+\"/Ausland2neu.csv\", sep=',', header=0) #Ausland2neu -> C\n",
    "dataframe_b[\"B14\"] = \"N\"*50 #LÖSCHEN!\n",
    "dataframe_c[\"C20\"] = \"N\"*50 #LÖSCHEN!\n",
    "dataframe_c[\"C21\"] = \"N\"*50 #LÖSCHEN!\n",
    "dataframe_d = pandas.read_csv(path+'/D.csv', sep=',', header=0)\n",
    "dataframe_e = pandas.read_csv(path+'/E.csv', sep=',', header=0)\n",
    "\n",
    "\n",
    "def C_20_Pos13(row):\n",
    "    B_Satz2Row = dataframe_b.loc[dataframe_b[\"B2\"] == row[\"C2A\"]].iloc[0]\n",
    "    temp_list = list(row[\"C20\"])\n",
    "    temp_list[12] = \"Y\" if B_Satz2Row[\"B14\"][1] == \"Y\" and row[\"C21\"][17] == \"N\" else \"N\"\n",
    "    return ''.join(temp_list)\n",
    "\n",
    "\n",
    "dataframe_c[\"C20\"] = dataframe_c.apply(C_20_Pos13, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "143785c541f94c98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# drop all values from dataframe_d\n",
    "#dataframe_d = dataframe_d.iloc[0:0]\n",
    "# kundennummer bei B2 und C2A verbinde dort nicht alle C2A sind in B2 enthalten\n",
    "dataframe_b['B2'] = dataframe_b['B2'].astype(str)\n",
    "dataframe_c['C2A'] = dataframe_c['C2A'].astype(str)\n",
    "dataframe_d['D1'] = 'D'\n",
    "dataframe_b[\"B1\"] = \"B\"\n",
    "dataframe_c[\"C1\"] = \"C\"\n",
    "dataframe_a[\"A1\"] = \"A\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d035ee0c8f9a560"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_a_b_c_data():\n",
    "    global dataframe_a_b_c\n",
    "    global dataframe_b_c\n",
    "    # verbinde die den dataframe B und C anhand der werte aus B2 und C2A\n",
    "    dataframe_b_c = pandas.merge(dataframe_b, dataframe_c, left_on='B2', right_on='C2A', how='inner')\n",
    "    # Repliziere dataframe_a für die Anzahl der Zeilen in dataframe_b_c\n",
    "    df_a_repeated_for_b_c = pandas.concat([dataframe_a] * dataframe_b_c.shape[0], ignore_index=True)\n",
    "    # Verbinde df_a_repeated_for_b_c horizontal mit dataframe_b_c\n",
    "    dataframe_a_b_c = pandas.concat([df_a_repeated_for_b_c, dataframe_b_c], axis=1)\n",
    "    # save dataframe b to csv\n",
    "generate_a_b_c_data()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf05fb3c384da98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######D2########\n",
    "# trage in D2 die einzigartigen werte aus B2 ein\n",
    "dataframe_d['D2'] = dataframe_a_b_c['B2'].unique()\n",
    "\n",
    "#######D3#######\n",
    "# D3 hat die summe aller werte aus C19 abhängig von der kundennummer\n",
    "dataframe_d['D3'] = dataframe_a_b_c.groupby('B2')['C19'].transform('sum')\n",
    "#######D4-15#######\n",
    "def compute_d_group(group, df_d):\n",
    "    # Initialize D4 value\n",
    "    D4_value = 0.00\n",
    "    D3_value = df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0]\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in ['01', '10']:\n",
    "\n",
    "        # Check if any value in B14 (range \"01\" to \"30\") is \"Y\"\n",
    "        if any(\"Y\" in s for s in group['B14'].str[0:30]):\n",
    "            D4_value = group['C19'].sum()\n",
    "        elif int(df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0]) < 20 and group['C20'].iloc[0] == 'Y':\n",
    "            D4_value = df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0]\n",
    "        elif any(\"Y\" in s for s in group['C20'].str[1:30]):\n",
    "            D4_value = group['C19'].sum()\n",
    "    else:\n",
    "        D4_value = 0.00\n",
    "\n",
    "    # Set D4 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D4'] = D4_value\n",
    "\n",
    "    D5_value = 0.00\n",
    "\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in ['01', '10']:\n",
    "        # Calculate D3 divided by D4\n",
    "        if D4_value != 0:\n",
    "            D5_value = D3_value / D4_value\n",
    "    else:\n",
    "        D5_value = 0.00\n",
    "\n",
    "    # Set D5 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D5'] = D5_value\n",
    "\n",
    "\n",
    "    D6_value = 0.00\n",
    "\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in ['01', '10']:\n",
    "        # Get the D5 value\n",
    "        # Calculate the limit which is A4 * C5\n",
    "        limit_value = group['A4'].iloc[0] * group['C5'].iloc[0]\n",
    "        # Set D6 to be the minimum of D5 and the limit value\n",
    "        D6_value = min(D5_value, limit_value)\n",
    "    else:\n",
    "        D6_value = 0.00\n",
    "\n",
    "    # Set D6 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D6'] = D6_value\n",
    "\n",
    "    D7_value = 0.00\n",
    "\n",
    "    # Check for \"01\" or \"10\" in A3\n",
    "    if str(group['A3'].iloc[0]) in [\"01\", \"10\"]:\n",
    "        # Get the D5 and D6 values\n",
    "        # Avoid division by zero\n",
    "        if D6_value != 0:\n",
    "            D7_value = D5_value / D6_value\n",
    "    else:\n",
    "        D7_value = 0.00\n",
    "\n",
    "    # Set D7 value in dataframe_d\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D7'] = D7_value\n",
    "\n",
    "    D8_value = 0.00\n",
    "    if pandas.notnull(group['C22'].iloc[0]) and group['C22'].iloc[0] != \"DE\":\n",
    "        D8_value = group['C19'].sum()\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D8'] = D8_value\n",
    "\n",
    "    D9_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) == \"20\":\n",
    "        limit_value = group['A5'].iloc[0] * group['C5'].iloc[0]\n",
    "        D9_value = min(df_d[df_d['D2'] == group['B2'].iloc[0]]['D3'].iloc[0], limit_value)\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D9'] = D9_value\n",
    "\n",
    "    D10_value = 0.00\n",
    "\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        D10_value = group[group['C27'] == 10]['C19'].sum()\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D10'] = D10_value\n",
    "\n",
    "    D11_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        D11_value = group[group['C27'] == 20]['C19'].sum() - group['C26'].sum()\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D11'] = D11_value\n",
    "\n",
    "\n",
    "    D14A_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        # Sum of debitorische Kontosalden from C19\n",
    "        D14A_value = -group['C19'].sum()\n",
    "    else:\n",
    "        D14A_value = 0.00\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D14A'] = D14A_value\n",
    "\n",
    "    wert1 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D3'].iloc[0]\n",
    "    wert2 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D10'].iloc[0]\n",
    "    wert3 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D14A'].iloc[0]\n",
    "    wert4 = max(df_d.loc[df_d['D2'] == group['B2'].iloc[0], ['D6', 'D9', 'D11']].iloc[0])\n",
    "    HW1 = wert1 - wert2 + wert3 - wert4\n",
    "    D12A_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        wert5 = df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D6'].iloc[0] + df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D9'].iloc[0]\n",
    "        if wert5 != 0:\n",
    "            limit_value = (group['A6C'].iloc[0] * group['C5'].iloc[0]) / wert5\n",
    "            D12A_value = min(HW1, limit_value)\n",
    "        else:\n",
    "            D12A_value = HW1\n",
    "        if D12A_value < 0:\n",
    "            D12A_value = 0.00\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D12A'] = D12A_value\n",
    "\n",
    "    D12B_value = 0.00\n",
    "    HW2 = group[(group['C27'].isin(['01', '90'])) & (group['C21'].str[18] == 'Y')]['C19'].sum()\n",
    "    # Berechne HW3\n",
    "    HW3_1 = group[(group['C27'] == '90') & (group['C21'].str[10] == 'N') & (group['C21'].str[18] == 'N')]['C19'].sum()\n",
    "    HW3_2 = group[group['C27'] == '20']['C19'].sum()\n",
    "    HW3 = HW3_1 + HW3_2\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"] and pandas.notnull(group['A8'].iloc[0]):\n",
    "        # Berechne HW2\n",
    "        # Werte für die Berechnung\n",
    "        A9_value = group['A9A'].iloc[0]\n",
    "        C5_value = group['C5'].iloc[0]\n",
    "\n",
    "        # Berechne die drei möglichen Werte für D12B\n",
    "        value1 = HW1 / D12A_value\n",
    "        value2 = HW2 / (D6_value + D9_value / HW3) if HW3 != 0 and (D6_value + D9_value / HW3) > 0 else HW2\n",
    "        value3 = A9_value * C5_value / (D6_value + D9_value + D12A_value)\n",
    "\n",
    "        # Setze D12B auf den kleinsten Wert\n",
    "        D12B_value = min(value1, value2, value3)\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D12B'] = D12B_value\n",
    "\n",
    "    D12C_value = 0.00\n",
    "\n",
    "    #convert c27 to string\n",
    "\n",
    "    # Berechne HW4\n",
    "    HW4 = group[(group['C27'].astype(str).isin(['01', '90'])) & (group['C21'].str[10] == 'Y')]['C19'].sum()\n",
    "\n",
    "    # Berechne HW5\n",
    "    HW5_1 = group[(group['C27'].astype(str) == '90') & (group['C21'].str[10] == 'N')]['C19'].sum()\n",
    "    HW5_2 = group[group['C27'].astype(str) == '20']['C19'].sum()\n",
    "    HW5 = HW5_1 + HW5_2\n",
    "\n",
    "\n",
    "\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"] and any('Y' == c for c in group['C21'].str[10]) and HW1 < int(group['A6C'].iloc[0]) * group['C5'].sum():  #welcher c5 wert soll genommen werden\n",
    "        # Werte für die Berechnung\n",
    "        C5_value = group['C5'].iloc[0]\n",
    "        A7_value = group['A7'].iloc[0]\n",
    "\n",
    "        wert2 = HW4 / ((D6_value + D9_value) / HW5) if (D6_value + D9_value) / HW5 > 0 else HW4\n",
    "        wert3 = A7_value * C5_value / (D6_value + D9_value + D12A_value + D12B_value)\n",
    "\n",
    "        # Setze D12C auf den kleinsten Wert\n",
    "        D12C_value = min(wert1, wert2, wert3)\n",
    "        if D12C_value < 0:\n",
    "            D12C_value = 0.00\n",
    "\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D12C'] = D12C_value\n",
    "\n",
    "\n",
    "    D13_value = 0.00\n",
    "    if str(group['A3'].iloc[0]) in [\"10\", \"20\"]:\n",
    "        D13_value = D12A_value + D12B_value + D12C_value\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D13'] = D13_value\n",
    "\n",
    "\n",
    "    valid_entries = group.loc[pandas.isnull(group['C23'])]\n",
    "    D15_value = valid_entries['C19'].sum()\n",
    "    df_d.loc[df_d['D2'] == group['B2'].iloc[0], 'D15'] = D15_value\n",
    "\n",
    "\n",
    "dataframe_a_b_c.groupby('B2').apply(compute_d_group, dataframe_d)\n",
    "\n",
    "dataframe_d['D1'] = 'D'\n",
    "dataframe_d.to_csv(path+'/D.csv', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a17ebc611c40296"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe_e = pandas.DataFrame(columns=['E1', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12A', 'E12B', 'E12C', 'E13', 'E14', 'E15'])\n",
    "\n",
    "# Setze die Werte für die Spalten in E\n",
    "dataframe_e.at[0, 'E1'] = 'E'\n",
    "# E2 wird freigelassen, wie du erwähnt hast\n",
    "dataframe_e.at[0, 'E3'] = dataframe_d['D3'].sum()\n",
    "dataframe_e.at[0, 'E4'] = dataframe_d['D4'].sum()\n",
    "dataframe_e.at[0, 'E5'] = dataframe_d['D5'].sum()\n",
    "dataframe_e.at[0, 'E6'] = dataframe_d['D6'].sum()\n",
    "dataframe_e.at[0, 'E7'] = dataframe_d['D7'].sum()\n",
    "dataframe_e.at[0, 'E8'] = dataframe_d['D8'].sum()\n",
    "dataframe_e.at[0, 'E9'] = dataframe_d['D9'].sum()\n",
    "dataframe_e.at[0, 'E10'] = dataframe_d['D10'].sum()\n",
    "dataframe_e.at[0, 'E11'] = dataframe_d['D11'].sum()\n",
    "dataframe_e.at[0, 'E12A'] = dataframe_d['D12A'].sum()\n",
    "dataframe_e.at[0, 'E12B'] = dataframe_d['D12B'].sum()\n",
    "dataframe_e.at[0, 'E12C'] = dataframe_d['D12C'].sum()\n",
    "dataframe_e.at[0, 'E13'] = dataframe_d['D13'].sum()\n",
    "dataframe_e.at[0, 'E14'] = dataframe_d['D14A'].sum()\n",
    "dataframe_e.at[0, 'E15'] = dataframe_d['D15'].sum()\n",
    "\n",
    "dataframe_e.to_csv(path+'/E.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e4459a822131"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\", encoding=\"ISO-8859-1\") as file:\n",
    "    file.write(\"\\t\".join(dataframe_a.iloc[0].astype(str)) + \"\\n\")\n",
    "    # Gruppieren nach allen B-Spalten\n",
    "    grouped = dataframe_a_b_c.groupby(list(dataframe_a_b_c.columns[dataframe_a_b_c.columns.str.startswith('B')]))\n",
    "    for _, group in grouped:\n",
    "        # Schreibe die B-Werte in die Datei\n",
    "        b_values = group.iloc[0][dataframe_a_b_c.columns.str.startswith('B')].astype(str)\n",
    "        file.write(','.join(b_values) + '\\n')\n",
    "\n",
    "        # Schreibe die C-Werte in die Datei\n",
    "        for _, row in group.iterrows():\n",
    "            c_values = row[dataframe_a_b_c.columns.str.startswith('C')].astype(str)\n",
    "            file.write(','.join(c_values) + '\\n')\n",
    "\n",
    "        # Schreibe die D-Werte in die Datei\n",
    "        b2_value = group['B2'].iloc[0]\n",
    "        d_row = dataframe_d[dataframe_d['D2'] == b2_value]\n",
    "        d_values = d_row.iloc[0].astype(str)\n",
    "        file.write(','.join(d_values) + '\\n')\n",
    "\n",
    "    # Schreibe die E-Werte in die Datei\n",
    "    for _, row in dataframe_e.iterrows():\n",
    "        e_values = row.astype(str)\n",
    "        file.write(','.join(e_values) + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e47ba0e3b76d47e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#berechne die endzeit\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83776283aa11f4b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
